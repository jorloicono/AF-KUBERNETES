## 1. Creaci√≥n de m√°quinas virtuales en Google Cloud Platform (GCP)

### 1.1. Acceder a Google Cloud Console

* Entra en [https://console.cloud.google.com/](https://console.cloud.google.com/)
* Selecciona o crea un proyecto nuevo (por ejemplo, `k8s-lab`).

---

### 1.2. Crear las instancias de m√°quina virtual (VM)

Para este laboratorio necesitas al menos **2 m√°quinas**:

* 1 Nodo de Control (control plane)
* 1 Nodo Trabajador (worker)

---

### 1.3. Configuraci√≥n de cada VM

* Ve a **Compute Engine > Instancias de VM > Crear instancia**.

* Pon nombre para la VM: por ejemplo, `k8s-control` y `k8s-worker1`.

* Regi√≥n: escoge la que est√© m√°s cerca o donde quieras.

* Tipo de m√°quina: selecciona al menos **2 vCPU y 7.5 GB RAM** (por ejemplo, e2-standard-2).

  > Esto asegura que Kubernetes pueda correr sin problemas. M√°s CPU y RAM ayudan a evitar errores por recursos limitados.

* En **Disco de arranque** selecciona:

  * Imagen: Ubuntu 24.04 LTS
  * Tama√±o del disco: m√≠nimo 20 GB (para tener espacio suficiente)

* En **Firewall**:

  * Marca las casillas para permitir tr√°fico HTTP y HTTPS (esto puede simplificar pruebas de red).
  * M√°s adelante abriremos el firewall para puertos Kubernetes.

* Opcional: En la pesta√±a "Administraci√≥n, seguridad, disco, red, sola ubicaci√≥n":

  * Bajo **Redes** aseg√∫rate que la VM est√° en la misma red o VPC que otras m√°quinas.

* **Crea** la instancia.

---

### 1.4. Crear una clave SSH para conectarse

* Si tienes Windows y vas a usar **PuTTY**, primero crea un par de claves SSH:

1. Descarga **PuTTYgen**: [https://www.puttygen.com/](https://www.puttygen.com/)
2. Abre PuTTYgen y haz clic en **Generate** para crear un par de claves.
3. Guarda la clave privada (.ppk) en tu PC.
4. Copia la clave p√∫blica (el texto que sale en PuTTYgen, que empieza por `ssh-rsa ...`).

---

### 1.5. Agregar clave p√∫blica SSH a las VM de GCP

* En Google Cloud Console, ve a **Compute Engine > Instancias de VM**.
* Haz clic en la VM `k8s-control`.
* Ve a la pesta√±a **Editar**.
* En la secci√≥n **Claves SSH**, pega tu clave p√∫blica generada con PuTTYgen.
* Guarda los cambios.
* Repite para la VM `k8s-worker1`.

---

## 2. Configuraci√≥n de Firewall en GCP para Kubernetes

Para que los nodos puedan comunicarse y Kubernetes funcione:

* Ve a **VPC Network > Reglas de firewall > Crear regla de firewall**.
* Pon un nombre, por ejemplo `allow-k8s`.
* Red: selecciona la red donde est√°n tus VM.
* Objetivos: "Todas las instancias en la red" (o solo las instancias espec√≠ficas si quieres seguridad).
* Filtros de fuente: deja en 0.0.0.0/0 para abrir desde cualquier IP (no recomendado para producci√≥n, solo para laboratorio).
* Protocolos y puertos:

  * Marca TCP y escribe: `22,6443,2379-2380,10250,10251,10252,10255`
  * Esto abre los puertos b√°sicos que Kubernetes usa para comunicaci√≥n entre nodos.
* Crea la regla.

---

## 3. Conexi√≥n a las m√°quinas usando PuTTY (Windows)

### 3.1. Configurar PuTTY para conectarse

* Abre PuTTY.
* En "Host Name (or IP address)", escribe la IP p√∫blica de la VM `k8s-control` (la puedes ver en Google Cloud Console).
* En **Connection > SSH > Auth**, busca la clave privada `.ppk` que guardaste con PuTTYgen.
* Guarda la sesi√≥n con un nombre (ejemplo: `k8s-control`).
* Haz clic en **Open**.

> La primera vez te preguntar√° si conf√≠as en la clave: acepta.

### 3.2. Usuario para login

* El usuario suele ser `ubuntu` en las im√°genes oficiales de Ubuntu.
* Si pediste un nombre distinto o configuraste otro usuario, √∫salo.
* Ejemplo de login:

```bash
login as: ubuntu
```

---

## 4. Instalaci√≥n Kubernetes con kubeadm

---

### 4.1. Actualizaci√≥n del sistema operativo

```bash
sudo -i
apt update && apt upgrade -y
```

**¬øPor qu√©?**

* Para asegurarnos de que el sistema operativo tiene los √∫ltimos parches de seguridad y actualizaciones, lo que evita problemas por bugs o vulnerabilidades.

---

### 4.2. Instalaci√≥n de dependencias b√°sicas

```bash
apt install -y apt-transport-https ca-certificates software-properties-common socat curl
```

**¬øPor qu√©?**

* Estas herramientas son necesarias para poder instalar software desde repositorios HTTPS, manejar certificados y descargar archivos (curl).

---

### 4.3. Desactivar swap

```bash
swapoff -a
```

**¬øPor qu√©?**

* Kubernetes no funciona bien con swap activado porque puede confundir el manejo de memoria y provocar que el kubelet marque errores o el scheduler no funcione correctamente.

---

### 4.4. Activar m√≥dulos del kernel y par√°metros de red

```bash
modprobe overlay
modprobe br_netfilter
```

Configura sysctl:

```bash
cat <<EOF | tee /etc/sysctl.d/kubernetes.conf
net.bridge.bridge-nf-call-ip6tables=1
net.bridge.bridge-nf-call-iptables=1
net.ipv4.ip_forward=1
EOF

sysctl --system
```

**¬øPor qu√©?**

* Kubernetes necesita que las reglas de iptables puedan pasar el tr√°fico entre interfaces de red en la capa de puente.
* Tambi√©n habilitamos el reenv√≠o de paquetes IP para la comunicaci√≥n entre pods.

---

### 4.5. Instalaci√≥n y configuraci√≥n de `containerd` (runtime de contenedores)

```bash
mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list
apt update
apt install -y containerd.io
containerd config default | tee /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
systemctl restart containerd
```

**¬øPor qu√©?**

* Kubernetes necesita un runtime de contenedores para ejecutar los pods.
* `containerd` es un runtime popular, liviano y recomendado por Kubernetes y GCP.
* Configuramos `systemd` para que el cgroup manager funcione correctamente con Kubernetes.

---

### 4.6. Instalaci√≥n de Kubernetes (kubeadm, kubelet, kubectl)

```bash
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list
apt update
apt install -y kubeadm=1.32.1-1.1 kubelet=1.32.1-1.1 kubectl=1.32.1-1.1
apt-mark hold kubeadm kubelet kubectl
```

**¬øPor qu√©?**

* Instalamos versiones espec√≠ficas para asegurar compatibilidad.
* `kubeadm` permite configurar el cl√∫ster.
* `kubelet` es el agente que corre en cada nodo.
* `kubectl` es la herramienta cliente para interactuar con el cl√∫ster.
* Bloqueamos las versiones para evitar actualizaciones autom√°ticas que rompan el cl√∫ster.

---

### 4.7. Configurar hostname e IP en `/etc/hosts`

```bash
hostname -i
vim /etc/hosts
```

Agrega l√≠neas, por ejemplo:

```
10.128.0.3 k8scp cp
```

**¬øPor qu√©?**

* Para que los nodos puedan resolverse por nombre dentro del cl√∫ster, facilitando la comunicaci√≥n y configuraci√≥n.

---

### 4.8. Inicializar el nodo de control con kubeadm

```bash
kubeadm init --config=kubeadm-config.yaml --upload-certs --node-name=cp
```

**¬øPor qu√©?**

* `kubeadm init` configura el nodo de control.
* El archivo `kubeadm-config.yaml` contiene par√°metros de configuraci√≥n como versi√≥n de Kubernetes, red de pods, etc.
* `--upload-certs` permite compartir certificados con nodos trabajadores que se unan.
* `--node-name` asigna un nombre al nodo.

---

### 4.9. Configurar kubectl para el usuario normal

```bash
mkdir -p $HOME/.kube
sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

**¬øPor qu√©?**

* Esto configura la herramienta `kubectl` para que puedas administrar el cl√∫ster sin ser root.

---

### 4.10. Instalar el plugin de red Cilium

```bash
kubectl apply -f cilium-cni.yaml
```

**¬øPor qu√©?**

* Kubernetes requiere un plugin de red para que los pods puedan comunicarse entre nodos.
* Cilium es un plugin avanzado con soporte para pol√≠ticas de red basadas en eBPF.

---

### 4.11. Configurar autocompletado de kubectl

```bash
sudo apt install bash-completion -y
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
```

**¬øPor qu√©?**

* Facilita la escritura de comandos con sugerencias autom√°ticas.

---


Con esto tienes:

* Las m√°quinas VM en GCP configuradas con Ubuntu 24.04.
* Conexi√≥n segura desde Windows con PuTTY.
* Firewall preparado para Kubernetes.
* Instalaci√≥n completa de Kubernetes usando kubeadm.
* Nodo control listo para unir trabajadores y desplegar aplicaciones.

---

## 5. Agregar un Nodo Worker al Cl√∫ster de Kubernetes

En este apartado conectaremos una segunda instancia (nodo worker), instalaremos el software necesario y lo uniremos al cl√∫ster Kubernetes creado en el nodo `control plane`.

---

### 5.1. Conectar al Nodo Worker

Con√©ctate a tu segundo nodo (por ejemplo, `k8s-worker1`) usando **PuTTY** (Windows) o SSH (Linux/Mac), tal como hiciste con el nodo `k8s-control`.


```bash
student@worker:~$ sudo -i
````

---

### 5.2. Actualizar el sistema

```bash
apt-get update && apt-get upgrade -y
```

> Permite aplicar actualizaciones del sistema. Si te pregunta, permite reiniciar servicios y conservar la configuraci√≥n local.

---

### 5.3. Instalar containerd y dependencias

```bash
apt install apt-transport-https software-properties-common ca-certificates tree socat -y
swapoff -a
modprobe overlay
modprobe br_netfilter
```

---

### 5.4. Configurar par√°metros de red para Kubernetes

```bash
cat <<EOF | tee /etc/sysctl.d/kubernetes.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sysctl --system
```

---

### 5.5. Instalar containerd (runtime de contenedores)

```bash
mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg

echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" \
| tee /etc/apt/sources.list.d/docker.list > /dev/null

apt-get update
apt-get install containerd.io -y

containerd config default | tee /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
systemctl restart containerd
```

---

### 5.6. Instalar Kubernetes (kubeadm, kubelet, kubectl)

```bash
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | \
gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] \
https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /" \
| tee /etc/apt/sources.list.d/kubernetes.list

apt-get update

apt-get install -y kubeadm=1.32.1-1.1 kubelet=1.32.1-1.1 kubectl=1.32.1-1.1
apt-mark hold kubeadm kubelet kubectl
```

> üí° Es importante usar las **mismas versiones** que en el nodo de control.

---

### 5.7. Configurar DNS local para el nodo de control

Edita el archivo `/etc/hosts`:

```bash
vim /etc/hosts
```

Agrega estas l√≠neas con la IP privada del nodo `cp`:

```
10.128.0.3 k8scp
10.128.0.3 cp
```

> Esto permite que el nodo worker resuelva el nombre del nodo de control.

---

### 5.8. Obtener el comando de uni√≥n desde el nodo `cp`

En el nodo de control, ejecuta:

```bash
sudo kubeadm token create --print-join-command
```

Ejemplo de salida:

```bash
kubeadm join k8scp:6443 --token abcdef.0123456789abcdef \
--discovery-token-ca-cert-hash sha256:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

---

### 5.9. Ejecutar el comando para unir el nodo al cl√∫ster

En el nodo worker, ejecuta el comando anterior (con tu propio token y hash):

```bash
kubeadm join k8scp:6443 --token abcdef.0123456789abcdef \
--discovery-token-ca-cert-hash sha256:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX \
--node-name=worker
```

> üîí Este comando configura al nodo como parte del cl√∫ster y arranca el `kubelet`.

---

### 5.10. Verificar que el nodo se ha unido correctamente

En el nodo de control, ejecuta:

```bash
kubectl get nodes
```

> El nuevo nodo `worker` debe aparecer con estado `Ready`.

---

### 5.11: Probar `kubectl` en el nodo worker 

```bash
kubectl get nodes
```

> Esto fallar√° porque no tienes el archivo `.kube/config` en este nodo. Es normal.

Error esperado:

```bash
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

¬°Has unido exitosamente un nodo worker al cl√∫ster Kubernetes usando `kubeadm`!

---

## 6. Finalizar la configuraci√≥n del cl√∫ster Kubernetes

En este apartado verificaremos el estado del cl√∫ster, eliminaremos las restricciones del nodo control plane para permitir pods no infraestructurales, y aseguraremos que los componentes esenciales como DNS y Cilium est√©n funcionando correctamente.

---

### 6.1. Ver nodos disponibles y su estado

Ejecuta en el nodo control plane:

```bash
kubectl get nodes
````

Ejemplo de salida:

```
NAME     STATUS   ROLES                  AGE     VERSION
cp       Ready    control-plane          28m     v1.32.1
worker   Ready    <none>                 50s     v1.32.1
```

> Nota: El estado puede tardar uno o dos minutos en pasar de `NotReady` a `Ready`.

---

### 6.2. Ver detalles de un nodo espec√≠fico

Para ver detalles y estado del nodo `cp`:

```bash
kubectl describe node cp
```

Revisa la secci√≥n `Taints`. El nodo `cp` tiene por defecto un taint que impide correr pods que no sean de infraestructura:

```
Taints:
  node-role.kubernetes.io/control-plane:NoSchedule
```

Esto es por seguridad y para evitar saturar el nodo con pods que no sean cr√≠ticos.

---

## Paso 3: Remover taints para permitir pods normales en el nodo control plane

Para permitir que el nodo `cp` ejecute pods normales (solo en ambientes de entrenamiento):

1. Verifica los taints:

   ```bash
   kubectl describe node cp | grep -i taint
   ```

2. Elimina el taint con:

   ```bash
   kubectl taint nodes cp node-role.kubernetes.io/control-plane:NoSchedule-
   ```

3. Verifica que ya no existan taints:

   ```bash
   kubectl describe node cp | grep -i taint
   ```

> Nota: El signo `-` al final del taint indica que se remueve.

---

### 6.4. Verificar que los pods DNS y Cilium est√°n corriendo

Ejecuta:

```bash
kubectl get pods --all-namespaces
```

Ejemplo de salida esperada:

```
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   cilium-operator-788c7d7585-tnsph   1/1     Running   0          95m
kube-system   cilium-swjsj                       1/1     Running   0          95m
kube-system   coredns-5d78c9869d-dwds8           1/1     Running   0          100m
kube-system   coredns-5d78c9869d-t24p5           1/1     Running   0          100m
```

> Todos deben mostrar `STATUS: Running`.

---

### 6.5. Si los pods `coredns` est√°n en estado `ContainerCreating`

1. Elimina los pods `coredns` para que Kubernetes los recree autom√°ticamente:

   ```bash
   kubectl -n kube-system delete pod <nombre-pod-coredns-1> <nombre-pod-coredns-2>
   ```

2. Verifica nuevamente que est√©n en `Running`:

   ```bash
   kubectl get pods --all-namespaces
   ```

---

### 6.6. Revisar interfaces de red creadas por Cilium

En el nodo `cp` ejecuta:

```bash
ip a
```

Ver√°s interfaces con nombres como `cilium_net` y `cilium_vxlan` activas, que Cilium utiliza para la comunicaci√≥n en el cl√∫ster.

---

### 6.7: Configurar `crictl` para usar containerd correctamente

1. Configura el endpoint de runtime e imagen para `crictl` en ambos nodos (`cp` y `worker`):

```bash
sudo crictl config --set runtime-endpoint=unix:///run/containerd/containerd.sock \
--set image-endpoint=unix:///run/containerd/containerd.sock
```

2. Puedes verificar la configuraci√≥n con:

```bash
cat /etc/crictl.yaml
```

Salida esperada:

```yaml
runtime-endpoint: "unix:///run/containerd/containerd.sock"
image-endpoint: "unix:///run/containerd/containerd.sock"
timeout: 0
debug: false
pull-image-on-create: false
disable-pull-on-run: false
```

---

Con estos pasos, el cl√∫ster Kubernetes est√° finalizado, los nodos preparados y los servicios b√°sicos como DNS y red funcionando correctamente.

---

Claro, aqu√≠ tienes una explicaci√≥n detallada del prop√≥sito de cada paso del instructivo para lanzar una aplicaci√≥n simple con **nginx** en Kubernetes. El formato es Markdown, por lo que puedes copiarlo directamente en tu documentaci√≥n.

---

## 7. Lanzar una aplicaci√≥n simple (nginx) ‚Äì Explicaci√≥n paso a paso

---

### 7.1. Crear un deployment con nginx y verificar que est√© corriendo

```bash
kubectl create deployment nginx --image=nginx
kubectl get deployments
```

**Prop√≥sito**: Se crea un *Deployment* que administra un *Pod* corriendo la imagen `nginx`. Esto asegura alta disponibilidad y manejo autom√°tico del ciclo de vida del contenedor.

---

### 7.2. Ver detalles del deployment

```bash
kubectl describe deployment nginx
```

**Prop√≥sito**: Proporciona detalles extensos sobre el Deployment, como eventos recientes, estrategia de actualizaci√≥n, etiquetas, y definici√≥n de los Pods que maneja.

---

### 7.3. Ver eventos del cluster para ver el despliegue del pod

```bash
kubectl get events
```

**Prop√≥sito**: Permite revisar eventos del cl√∫ster relacionados con la creaci√≥n y el estado de los recursos, √∫til para diagnosticar errores o confirmar que todo va bien.

---

### 7.4. Ver el despliegue en formato YAML (√∫til para ver configuraci√≥n detallada)

```bash
kubectl get deployment nginx -o yaml
```

**Prop√≥sito**: Obtener la configuraci√≥n completa del Deployment en formato declarativo. Este formato es √∫til para edici√≥n, auditor√≠a o recreaci√≥n del recurso.

---

### 7.5. Guardar el YAML en un archivo, luego editarlo para eliminar las l√≠neas autom√°ticas

```bash
kubectl get deployment nginx -o yaml > first.yaml
vim first.yaml
```

**Editar**:
Eliminar metadatos generados autom√°ticamente:

* `creationTimestamp`
* `resourceVersion`
* `uid`
* Todo desde `status:` en adelante

**Prop√≥sito**: Al limpiar el YAML, este se puede reutilizar para crear nuevos recursos sin conflictos con informaci√≥n generada por el sistema.

---

### 7.6. Borrar el deployment actual

```bash
kubectl delete deployment nginx
```

**Prop√≥sito**: Elimina el Deployment original para probar la creaci√≥n a partir del archivo limpio (`first.yaml`).

---

### 7.7. Crear el deployment usando el archivo editado

```bash
kubectl create -f first.yaml
```

**Prop√≥sito**: Recrea el Deployment a partir del archivo YAML limpio, asegurando control completo sobre su configuraci√≥n.

---

### 7.8. Comparar el YAML nuevo con el anterior

```bash
kubectl get deployment nginx -o yaml > second.yaml
diff first.yaml second.yaml
```

**Prop√≥sito**: Verifica qu√© cambios ocurrieron autom√°ticamente al aplicar el recurso (nuevos UIDs, timestamps, etc.).

---

### 7.9. Generar YAML sin crear objeto usando --dry-run

```bash
kubectl create deployment two --image=nginx --dry-run=client -o yaml
```

**Prop√≥sito**: Permite generar un manifiesto YAML para revisi√≥n o versionado sin aplicarlo directamente en el cl√∫ster.

---

### 7.10. Ver el deployment nginx en YAML

```bash
kubectl get deployments nginx -o yaml
```

**Prop√≥sito**: Similar al paso 4, permite revisar o respaldar la configuraci√≥n actual.

---

### 7.11. Ver el deployment nginx en JSON

```bash
kubectl get deployment nginx -o json
```

**Prop√≥sito**: Alternativa al YAML, √∫til cuando se integran herramientas de automatizaci√≥n que prefieren formato JSON.

---

### 7.12. Consultar ayuda para exponer servicios

```bash
kubectl expose -h
```

**Prop√≥sito**: Muestra todas las opciones disponibles del comando `kubectl expose`, que convierte un recurso en un servicio accesible.

---

### 7.13. Intentar exponer el deployment sin especificar puerto

```bash
kubectl expose deployment/nginx
```

**Resultado esperado**: Error indicando que no se puede encontrar un puerto.

**Prop√≥sito**: Ilustra que para exponer un Deployment como servicio, se debe especificar un puerto expl√≠citamente o definirlo previamente en el contenedor.

---

### 7.14. Editar el archivo YAML para a√±adir el puerto 80

```yaml
ports:
- containerPort: 80
  protocol: TCP
```

**Prop√≥sito**: Se a√±ade la especificaci√≥n de puerto necesario para que `kubectl expose` funcione correctamente.

---

### 7.15. Reemplazar el deployment con el archivo modificado (forzado)

```bash
kubectl replace -f first.yaml --force
```

**Prop√≥sito**: Elimina y vuelve a crear el recurso, √∫til cuando se necesita aplicar cambios estructurales profundos.

---

### 7.16. Ver pods y deployment

```bash
kubectl get deploy,pod
```

**Prop√≥sito**: Confirma que el nuevo Pod se est√° ejecutando y est√° vinculado al Deployment correctamente.

---

### 7.17. Ahora exponer el deployment

```bash
kubectl expose deployment/nginx
```

**Prop√≥sito**: Crea un *Service* tipo `ClusterIP` que permite acceso interno al Deployment por medio de un nombre DNS.

---

### 7.18. Ver configuraci√≥n del servicio y endpoints

```bash
kubectl get svc nginx
kubectl get ep nginx
```

**Prop√≥sito**: Verifica que el *Service* est√© creado correctamente y que est√© enlazado a uno o m√°s Pods disponibles.

---

### 7.19. Probar acceso al servicio usando curl

```bash
curl 10.100.61.122:80
curl 192.168.1.5:80
```

**Prop√≥sito**: Comprueba que el servicio y el pod est√°n respondiendo correctamente. Debe devolver la p√°gina de bienvenida de nginx.

---

### 7.20. Escalar el deployment a 3 r√©plicas

```bash
kubectl scale deployment nginx --replicas=3
kubectl get deployment nginx
```

**Prop√≥sito**: Demuestra c√≥mo escalar una aplicaci√≥n para soportar mayor carga o disponibilidad.

---

### 7.21. Ver endpoints (deber√≠an mostrar 3 IPs)

```bash
kubectl get ep nginx
```

**Prop√≥sito**: Confirma que los nuevos Pods se han agregado al Service y est√°n accesibles.

---

### 7.22. Eliminar el pod m√°s antiguo

```bash
kubectl get pods -o wide
kubectl delete pod <nombre-del-pod-antiguo>
```

**Prop√≥sito**: Simula una falla o reinicio manual de un Pod, √∫til para observar c√≥mo el Deployment mantiene el estado deseado.

---

### 7.23. Esperar a que se cree un nuevo pod

```bash
kubectl get pods
```

**Prop√≥sito**: Verifica que Kubernetes reemplaza autom√°ticamente Pods eliminados para mantener la cantidad especificada.

---

### 7.24. Ver endpoints otra vez

```bash
kubectl get ep nginx
```

**Prop√≥sito**: Confirma que el nuevo Pod reemplaz√≥ al anterior y que el Service sigue funcionando correctamente.

---

## 8. Acceder desde el exterior Cluster

Acceso a un Servicio desde fuera del cl√∫ster usando variables de entorno y LoadBalancer

---

### 8.1. Listar los pods actuales

```bash
kubectl get pods
```

**¬øPor qu√©?**
Para conocer qu√© pods est√°n corriendo actualmente, su estado y edad. Necesitamos saber qu√© pods est√°n disponibles para interactuar con ellos o para probar el acceso.

---

### 8.2. Ejecutar un comando dentro de un pod para ver variables de entorno relacionadas con Kubernetes

```bash
kubectl exec nginx-1423793266-13p69 -- printenv | grep KUBERNETES
```

**¬øPor qu√©?**
Las variables de entorno como `KUBERNETES_SERVICE_HOST` y `KUBERNETES_SERVICE_PORT` son inyectadas autom√°ticamente dentro de los pods para que las aplicaciones puedan descubrir y comunicarse con el API Server de Kubernetes. Verlas confirma que el pod est√° configurado correctamente para comunicarse con el cl√∫ster.

---

### 8.3. Ver el servicio (Service) actual de nginx

```bash
kubectl get svc
```

**¬øPor qu√©?**
Un Service en Kubernetes es el objeto que expone los pods para que puedan ser accedidos. Aqu√≠ vemos qu√© servicios est√°n disponibles y c√≥mo est√°n configurados (tipo, IP, puertos).

---

### 8.4. Eliminar el servicio nginx actual

```bash
kubectl delete svc nginx
```

**¬øPor qu√©?**
Vamos a eliminar el servicio actual para recrearlo con una configuraci√≥n diferente (tipo `LoadBalancer`) que nos permitir√° acceder a la aplicaci√≥n desde fuera del cl√∫ster.

---

### 8.5. Crear el servicio nuevamente, pero esta vez con tipo LoadBalancer

```bash
kubectl expose deployment nginx --type=LoadBalancer
```

**¬øPor qu√©?**
El tipo `LoadBalancer` crea un servicio que intenta asignar una IP externa accesible fuera del cl√∫ster, ideal para exponer aplicaciones al mundo exterior (por ejemplo, Internet). Si est√°s en una nube p√∫blica, el proveedor asignar√° autom√°ticamente la IP p√∫blica.

---

### 8.6. Verificar el servicio para ver la IP externa y puertos

```bash
kubectl get svc
```

**¬øPor qu√©?**
Para confirmar que el servicio `LoadBalancer` fue creado y revisar la IP externa (o el estado `pending` si no est√° asignada todav√≠a) y el puerto expuesto. Tambi√©n muestra el puerto interno y el puerto NodePort asignado para acceso externo.

---

### 8.7. Acceder al servicio desde fuera del cl√∫ster

* Obtener IP p√∫blica (por ejemplo, con `curl ifconfig.io`)
* Usar la IP p√∫blica y el puerto NodePort para acceder v√≠a navegador o `curl`.

**¬øPor qu√©?**
El objetivo es probar el acceso real desde fuera del entorno de Kubernetes al servicio desplegado, confirmando que la configuraci√≥n LoadBalancer y NodePort funciona correctamente.

---

### 8.8. Escalar el deployment a 0 r√©plicas (apagar nginx)

```bash
kubectl scale deployment nginx --replicas=0
kubectl get pods
```

**¬øPor qu√©?**
Al escalar a 0 se terminan todos los pods, lo que deber√≠a hacer que el servicio ya no tenga backend disponible y, por ende, no responda a las peticiones. Esto verifica que la conexi√≥n depende realmente de los pods activos.

---

### 8.9. Escalar el deployment a 2 r√©plicas (encender nginx)

```bash
kubectl scale deployment nginx --replicas=2
kubectl get pods
```

**¬øPor qu√©?**
Volver a levantar 2 pods permite restablecer el servicio y confirmar que el escalado din√°mico funciona y que el servicio vuelve a responder con m√∫ltiples r√©plicas.

---

### 8.10. Eliminar deployment y servicio para liberar recursos

```bash
kubectl delete deployment nginx
kubectl delete svc nginx
```

**¬øPor qu√©?**
Para limpiar el entorno y liberar los recursos asignados (CPU, memoria, IPs), evitando dejar objetos o servicios activos innecesarios.

